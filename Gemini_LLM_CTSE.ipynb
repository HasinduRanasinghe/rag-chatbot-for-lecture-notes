{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CTSE AI-ML Assignment"
      ],
      "metadata": {
        "id": "dlsUfvAkecyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction"
      ],
      "metadata": {
        "id": "dhwecpS8fNb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IT Number - IT21358920\n",
        "\n",
        "Name - Ranasinghe R. A. H. B.\n",
        "\n",
        "What is this about?\n",
        "\n",
        "* Chatbot for CTSE Lecture Notes\n",
        "* This notebook implements a Retrieval-Augmented Generation (RAG) system in Google Colab (Jupyter Notebook) to answer questions based on PDFs of CTSE lecture notes.\n",
        "* It uses Chroma for vector storage, google/gemini-2.0-flash for generation, and includes caching, verbose debugging, and Markdown-inspired output."
      ],
      "metadata": {
        "id": "ZWtjWP7yer_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 1: Install Dependencies"
      ],
      "metadata": {
        "id": "8CbVU2yjfU5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community chromadb sentence-transformers pypdf langchain-google-genai gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78Wxm6t1erjN",
        "outputId": "b11524c2-d2fe-4d2f-e20e-3f031bc16811"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.0.7)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.3)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.56)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.34)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi==0.115.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.9)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.21.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.16)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.16 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.17)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 2: Import Libraries"
      ],
      "metadata": {
        "id": "t2JNb7hffgYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Imports all necessary libraries for file handling, Google Drive integration, document processing,\n",
        "embeddings, vector storage, LLM setup, and RAG pipeline creation.\n",
        "\"\"\"\n",
        "import os\n",
        "import gdown\n",
        "from google.colab import drive\n",
        "from getpass import getpass\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "F9ZwGGKmemC6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 3: Set Up Environment"
      ],
      "metadata": {
        "id": "zRHJhyo8fs7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Configures the environment by mounting Google Drive for persistent storage, defining file paths,\n",
        "and downloading the CTSE lecture notes PDF. Initializes a cache for query responses.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zCOvPySlf_Vm",
        "outputId": "ae0d51b7-5c85-4b0f-d5f5-94551cec36da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nConfigures the environment by mounting Google Drive for persistent storage, defining file paths,\\nand downloading the CTSE lecture notes PDF. Initializes a cache for query responses.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive for persistent Chroma database storage\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7hkVfA9eXdM",
        "outputId": "c57ba05c-5b27-4277-842b-c5c45f4350ef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths and cache\n",
        "DATA_PATH = \"/content/CTSE_Lecture_Notes.pdf\"  # Path for downloaded PDF\n",
        "CHROMA_PATH = \"/content/drive/MyDrive/chroma_db_ctse_gemini\"  # Path for Chroma vector database\n",
        "CACHE = {}  # Dictionary to store cached query responses"
      ],
      "metadata": {
        "id": "odbHblaUf3za"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download lecture notes PDF from Google Drive\n",
        "file_id = \"1fy4CWBFzfS1cxMxRlPiRIVdS0e4zihzQ\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", DATA_PATH, quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iuCXuxVrf03i",
        "outputId": "38941f10-3ec4-4fd7-dfa9-d6aace503b9d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/CTSE_Lecture_Notes.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify PDF download\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    print(f\"Error: Failed to download lecture notes to {DATA_PATH}\")\n",
        "else:\n",
        "    print(f\"Lecture notes downloaded to {DATA_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp_tlc3ZeZiX",
        "outputId": "3accf920-7742-473b-cf94-f430f8a57c09"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lecture notes downloaded to /content/CTSE_Lecture_Notes.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Google API key for Gemini\n",
        "print(\"Enter your Google API key for Gemini:\")\n",
        "api_key = getpass(\"API Key: \")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d7p-VhuTKKH",
        "outputId": "f72afc81-fa8b-4b30-c51b-29c0ab385d04"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API key for Gemini:\n",
            "API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 4: Load and Split Documents"
      ],
      "metadata": {
        "id": "JdgppN25gGmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Loads the lecture notes PDF and splits it into manageable chunks for embedding. Uses a larger\n",
        "chunk size and overlap to preserve context, improving retrieval accuracy.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RXUP0BiTgNBc",
        "outputId": "31c19461-c044-48ce-da08-875a2e58f548"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nLoads the lecture notes PDF and splits it into manageable chunks for embedding. Uses a larger\\nchunk size and overlap to preserve context, improving retrieval accuracy.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PDF using PyPDFLoader\n",
        "print(\"Loading lecture notes...\")\n",
        "loader = PyPDFLoader(DATA_PATH)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtwXcfbygOOP",
        "outputId": "eabbc5c7-f153-4e59-bbba-dd074cc3ec0f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading lecture notes...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify document loading\n",
        "if not documents:\n",
        "    print(\"Error: No documents loaded from the PDF.\")\n",
        "else:\n",
        "    print(f\"Loaded {len(documents)} document pages.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ5KHfmKgPEl",
        "outputId": "0ed2c079-a296-4581-e36c-5c6fb6fab7f5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 408 document pages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split documents into chunks for embedding\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # Larger chunk size to retain context\n",
        "    chunk_overlap=200  # Overlap to ensure continuity between chunks\n",
        ")\n",
        "docs = splitter.split_documents(documents)\n",
        "print(f\"Split into {len(docs)} chunks.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SNb8OAleZXg",
        "outputId": "cc3b66df-435a-4130-fe18-52906cc80385"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split into 384 chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 5: Create Embeddings and Vector Store"
      ],
      "metadata": {
        "id": "GMrrjnWwgXnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Generates embeddings using Google's embedding-001 and stores them in a Chroma vector database,\n",
        "persisted to Google Drive. Configures a retriever to fetch relevant document chunks.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "EQqOAdkBgOHF",
        "outputId": "f02d9298-c5e0-453d-8dad-5d613c4ebaa0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nGenerates embeddings using Google's embedding-001 and stores them in a Chroma vector database,\\npersisted to Google Drive. Configures a retriever to fetch relevant document chunks.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize embedding model\n",
        "embedding_model_name = \"models/embedding-001\"\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=embedding_model_name)\n",
        "print(f\"Initialized embeddings: {embedding_model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC1gDNMAgdHn",
        "outputId": "3b3cdb4c-2d23-458c-a9e6-7c0b073adff1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized embeddings: models/embedding-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load or create Chroma vector store\n",
        "if os.path.exists(CHROMA_PATH):\n",
        "    print(f\"Loading vector store from {CHROMA_PATH}\")\n",
        "    vectorstore = Chroma(\n",
        "        persist_directory=CHROMA_PATH,\n",
        "        embedding_function=embeddings\n",
        "    )\n",
        "else:\n",
        "    print(f\"Creating vector store in {CHROMA_PATH}\")\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=docs,\n",
        "        embedding=embeddings,\n",
        "        persist_directory=CHROMA_PATH\n",
        "    )\n",
        "print(\"Vector store created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qbXSqTmgdBm",
        "outputId": "76e127f6-a62c-4e68-8541-adcb0ef7ca58"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating vector store in /content/drive/MyDrive/chroma_db_ctse_gemini\n",
            "Vector store created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure retriever to fetch top 5 relevant chunks\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "print(\"Retriever configured.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saZVe5FGeZRy",
        "outputId": "5e278eab-e1ff-4295-dadc-837ea2d0033f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retriever configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 6: Initialize Language Model"
      ],
      "metadata": {
        "id": "8t2MiDNDgnYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Sets up the google/gemini-2.0-flash model.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8XO_lVeZguGk",
        "outputId": "3dfcf7a9-00a0-44a3-fa54-cbc076e87dc4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSets up the google/gemini-2.0-flash model.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Gemini model\n",
        "model_id = \"gemini-2.0-flash\"\n",
        "print(f\"Initializing model: {model_id}\")\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=model_id,\n",
        "    temperature=0.7,\n",
        "    max_output_tokens=512,\n",
        "    top_p=0.95,\n",
        ")\n",
        "print(\"LLM initialized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raNlZOoMgt1O",
        "outputId": "732e51de-db8d-418a-a4b8-1d70a912b64e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing model: gemini-2.0-flash\n",
            "LLM initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 7: Configure RAG Chain"
      ],
      "metadata": {
        "id": "G2Wd2FZ-g6HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Sets up the RAG pipeline with a custom prompt to ensure answers are based solely on the provided\n",
        "context. Combines the retriever and LLM for retrieval-augmented generation.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qFAAFtang-cq",
        "outputId": "50dbdf3a-b789-48e1-9c35-748708d2f634"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSets up the RAG pipeline with a custom prompt to ensure answers are based solely on the provided\\ncontext. Combines the retriever and LLM for retrieval-augmented generation.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom prompt for RAG\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Context from Lecture Notes:\\n\"\n",
        "    \"{context}\\n\\n\"\n",
        "    \"Based on the above context, provide a concise answer (up to 3 sentences) to the following question.\\n\"\n",
        "    \"Summarize relevant information (e.g., bullet points, definitions) and answer ONLY the question asked.\\n\"\n",
        "    \"If the context does not contain the answer, respond with: \"\n",
        "    \"\\\"I cannot answer this question based on the provided notes.\\\"\\n\\n\"\n",
        "    \"Question: {input}\"\n",
        ")"
      ],
      "metadata": {
        "id": "KfDUpGOLg-T7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create document chain to process retrieved documents\n",
        "document_chain = create_stuff_documents_chain(llm, prompt)"
      ],
      "metadata": {
        "id": "CY5jiLP4hJhW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create RAG chain combining retriever and document chain\n",
        "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
        "print(\"RAG chain created. Ready to answer questions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOKLlMM2eY7X",
        "outputId": "6bb20b2b-2142-452c-b64c-7eb90b7efbab"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG chain created. Ready to answer questions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 8: Interactive Chat Loop"
      ],
      "metadata": {
        "id": "thAmrGrGhMjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Implements an interactive chat loop for user queries. Supports caching for efficiency, verbose mode\n",
        "for source document display, and a Markdown-inspired output format for clarity.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "9us-I4sweY0H",
        "outputId": "787aba63-2fb8-4fbb-f522-d066e0d43fd7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nImplements an interactive chat loop for user queries. Supports caching for efficiency, verbose mode\\nfor source document display, and a Markdown-inspired output format for clarity.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc1cusYWePWY",
        "outputId": "e2806e19-4bf4-4052-8e7d-891a99c9a030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================\n",
            "    ü§ñ CTSE Lecture Notes Chatbot    \n",
            "======================================\n",
            "Enter your question or 'exit' to quit.\n",
            "Append '--verbose' to see source documents.\n",
            "\n",
            "‚ùì Question: what is machine learning? --verbose\n",
            "\n",
            "‚è≥ Processing...\n",
            "\n",
            "Question: what is machine learning?\n",
            "\n",
            "Answer:\n",
            "Machine learning is a field of study that enables computers to learn without explicit programming, as defined by Arthur Samuel. It's a subfield of artificial intelligence focused on machines imitating intelligent human behavior. The core concept involves a computer program improving its performance (P) on a set of tasks (T) through experience (E).\n",
            "\n",
            "üìö Source Documents:\n",
            "\n",
            "- Source 1 (Page: 303):\n",
            "Lesson Objectives\n",
            "‚Ä¢ At the end of the lesson students \n",
            "should be able to explain\n",
            "‚Ä¢ What is Machine Learning?\n",
            "‚Ä¢ Why Choose Machine Learning?\n",
            "‚Ä¢ Different Machine Learning \n",
            "Algorithms and their applications\n",
            "----------------------------------------------------------------------------------------------------\n",
            "- Source 2 (Page: 306):\n",
            "What is Machine Learning\n",
            "‚Ä¢ ‚Äúfield of study that gives computers the ability to learn \n",
            "without explicitly being programmed.‚Äù by Arthur Samuel\n",
            "‚Ä¢ Machine learning is a subfield of artificial intelligence, \n",
            "which is broadly defined as the capability of a machine to \n",
            "imitate intelligent human behavior.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "- Source 3 (Page: 308):\n",
            "Computer\n",
            "Output\n",
            "Computer\n",
            "Data \n",
            "Program Output\n",
            "Data Program\n",
            "ML vs Traditional programming\n",
            "Traditional Programming\n",
            "Machine Learning Learning Algorithm\n",
            "7\n",
            "----------------------------------------------------------------------------------------------------\n",
            "- Source 4 (Page: 307):\n",
            "Learning in a \n",
            "Machine\n",
            "‚Ä¢ ‚ÄúA computer program is said to learn \n",
            "from experience (E) with some class of \n",
            "tasks (T) and a performance measure (P) \n",
            "if its performance at tasks in T as\n",
            "measured by P improves with E‚Äù\n",
            "6\n",
            "----------------------------------------------------------------------------------------------------\n",
            "- Source 5 (Page: 336):\n",
            "Applications of \n",
            "Machine Learning \n",
            "Models\n",
            "‚Ä¢ Predicting Numerical Values\n",
            "‚Ä¢ Identifying the type of a flower based\n",
            "on size, color, number of petals, ‚Ä¶etc.\n",
            "‚Ä¢ Classifying Flowers from Images\n",
            "‚Ä¢ Learning to predict the next word in a\n",
            "sequence\n",
            "‚Ä¢ Generate cartoon characters\n",
            "‚Ä¢ Classifying customers based on ...\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "üí° Ask another question or type 'exit' to quit!\n",
            "\n",
            "‚ùì Question: exit\n",
            "\n",
            "üëã Exiting. Goodbye!\n"
          ]
        }
      ],
      "source": [
        "# Print chatbot introduction\n",
        "print(\"\\n======================================\")\n",
        "print(\"    ü§ñ CTSE Lecture Notes Chatbot    \")\n",
        "print(\"======================================\")\n",
        "print(\"Enter your question or 'exit' to quit.\")\n",
        "print(\"Append '--verbose' to see source documents.\\n\")\n",
        "\n",
        "# Main loop for user interaction\n",
        "while True:\n",
        "    query = input(\"‚ùì Question: \")\n",
        "\n",
        "    # Handle exit command\n",
        "    if query.strip().lower() == 'exit':\n",
        "        print(\"\\nüëã Exiting. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Handle verbose mode and normalize query\n",
        "    verbose = False\n",
        "    if '--verbose' in query:\n",
        "        verbose = True\n",
        "        query = query.replace('--verbose', '').strip()\n",
        "\n",
        "    # Validate and normalize input\n",
        "    query = ' '.join(query.split())  # Remove extra spaces\n",
        "    if not query:\n",
        "        print(\"\\n‚ö†Ô∏è Error: Please enter a valid question.\")\n",
        "        continue\n",
        "\n",
        "    # Log processing\n",
        "    print(\"\\n‚è≥ Processing...\")\n",
        "\n",
        "    try:\n",
        "        # Check cache and validate response\n",
        "        if query in CACHE:\n",
        "            cached_answer = CACHE[query]['answer']\n",
        "            # Re-invoke if cached answer is the fallback response\n",
        "            if cached_answer == \"I cannot answer this question based on the provided notes.\":\n",
        "                result = rag_chain.invoke({\"input\": query})\n",
        "                CACHE[query] = {'answer': result['answer'], 'context': result['context']}\n",
        "            else:\n",
        "                print(f\"\\nQuestion: {query}\\n\")\n",
        "                print(\"Answer (Cached):\")\n",
        "                print(f\"{cached_answer}\\n\")\n",
        "                if verbose:\n",
        "                    print(\"üìö Source Documents (Cached):\")\n",
        "                    for i, doc in enumerate(CACHE[query]['context'], 1):\n",
        "                        print(f\"- Source {i} (Page: {doc.metadata.get('page', 'N/A')}):\")\n",
        "                        print(f\"{doc.page_content[:300]}{'...' if len(doc.page_content) > 300 else ''}\")\n",
        "                        print(\"\" + \"-\" * 100)\n",
        "                print(\"\\nüí° Ask another question or type 'exit' to quit!\\n\")\n",
        "                continue\n",
        "\n",
        "        # Invoke RAG chain\n",
        "        result = rag_chain.invoke({\"input\": query})\n",
        "\n",
        "        # Cache response\n",
        "        CACHE[query] = {\n",
        "            'answer': result['answer'],\n",
        "            'context': result['context']\n",
        "        }\n",
        "\n",
        "        # Print refined terminal-friendly output\n",
        "        print(f\"\\nQuestion: {query}\\n\")\n",
        "        print(\"Answer:\")\n",
        "        print(f\"{result['answer']}\\n\")\n",
        "        if verbose:\n",
        "            print(\"üìö Source Documents:\\n\")\n",
        "            for i, doc in enumerate(result['context'], 1):\n",
        "                print(f\"- Source {i} (Page: {doc.metadata.get('page', 'N/A')}):\")\n",
        "                print(f\"{doc.page_content[:300]}{'...' if len(doc.page_content) > 300 else ''}\")\n",
        "                print(\"\" + \"-\" * 100)\n",
        "        print(\"\\nüí° Ask another question or type 'exit' to quit!\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ö†Ô∏è Error: {e}\")\n",
        "        print(\"Please check your input, ensure the PDF is accessible, and verify your Hugging Face token.\")"
      ]
    }
  ]
}