{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ML"
      ],
      "metadata": {
        "id": "dlsUfvAkecyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 1: Install Dependencies"
      ],
      "metadata": {
        "id": "8CbVU2yjfU5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community chromadb pypdf langchain-google-genai gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78Wxm6t1erjN",
        "outputId": "bb2e0b02-ff5c-4f9d-87ce-9889c685f785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.0.9)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.5.0)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: fastapi==0.115.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.9)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.33.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.33.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.54b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.33.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.18)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.33.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.33.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.33.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.33.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.54b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.54b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.31.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 2: Import Libraries"
      ],
      "metadata": {
        "id": "t2JNb7hffgYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Imports all necessary libraries for file handling, Google Drive integration, document processing,\n",
        "embeddings, vector storage, LLM setup, and RAG pipeline creation.\n",
        "\"\"\"\n",
        "import os\n",
        "import gdown\n",
        "from google.colab import drive\n",
        "from getpass import getpass\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "F9ZwGGKmemC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 3: Set Up Environment"
      ],
      "metadata": {
        "id": "zRHJhyo8fs7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Configures the environment by mounting Google Drive for persistent storage, defining file paths,\n",
        "and downloading the CTSE lecture notes PDF. Initializes a cache for query responses.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "zCOvPySlf_Vm",
        "outputId": "32751d83-8688-47a0-e950-913d3c784d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nConfigures the environment by mounting Google Drive for persistent storage, defining file paths,\\nand downloading the CTSE lecture notes PDF. Initializes a cache for query responses.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive for persistent Chroma database storage\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7hkVfA9eXdM",
        "outputId": "1eac98e0-36df-41a5-c1a1-865dd4134a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths and cache\n",
        "DATA_PATH = \"/content/ML - Merged.pdf\"  # Path for downloaded PDF\n",
        "CHROMA_PATH = \"/content/drive/MyDrive/chroma_db_ml_gemini\"  # Path for Chroma vector database\n",
        "CACHE = {}  # Dictionary to store cached query responses"
      ],
      "metadata": {
        "id": "odbHblaUf3za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download lecture notes PDF from Google Drive\n",
        "file_id = \"1tu26YxQNFO1GbY-QFiJXGv8yV9OsvWaF\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", DATA_PATH, quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iuCXuxVrf03i",
        "outputId": "f44ba5aa-77e8-43ec-f6d9-5b40445c9d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/ML - Merged.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify PDF download\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    print(f\"Error: Failed to download lecture notes to {DATA_PATH}\")\n",
        "else:\n",
        "    print(f\"Lecture notes downloaded to {DATA_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp_tlc3ZeZiX",
        "outputId": "f3d1c107-f7c5-450a-85bc-069dac1da8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lecture notes downloaded to /content/ML - Merged.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Google API key for Gemini\n",
        "print(\"Enter your Google API key for Gemini:\")\n",
        "api_key = getpass(\"API Key: \")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d7p-VhuTKKH",
        "outputId": "a14d318f-065c-47f0-f46e-21eb04c38627"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API key for Gemini:\n",
            "API Key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 4: Load and Split Documents"
      ],
      "metadata": {
        "id": "JdgppN25gGmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Loads the lecture notes PDF and splits it into manageable chunks for embedding. Uses a larger\n",
        "chunk size and overlap to preserve context, improving retrieval accuracy.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RXUP0BiTgNBc",
        "outputId": "caee00ff-f53c-4465-c01c-8ad7b25112fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nLoads the lecture notes PDF and splits it into manageable chunks for embedding. Uses a larger\\nchunk size and overlap to preserve context, improving retrieval accuracy.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PDF using PyPDFLoader\n",
        "print(\"Loading lecture notes...\")\n",
        "loader = PyPDFLoader(DATA_PATH)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtwXcfbygOOP",
        "outputId": "af3ba297-f8ff-4c82-fe60-dd6260e02a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading lecture notes...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify document loading\n",
        "if not documents:\n",
        "    print(\"Error: No documents loaded from the PDF.\")\n",
        "else:\n",
        "    print(f\"Loaded {len(documents)} document pages.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ5KHfmKgPEl",
        "outputId": "ba21b70a-17b1-417e-f34c-da623a21937a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 757 document pages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split documents into chunks for embedding\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # Larger chunk size to retain context\n",
        "    chunk_overlap=200  # Overlap to ensure continuity between chunks\n",
        ")\n",
        "docs = splitter.split_documents(documents)\n",
        "print(f\"Split into {len(docs)} chunks.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SNb8OAleZXg",
        "outputId": "6fa15cf7-045e-4d61-bbee-ce4314be5391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split into 692 chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 5: Create Embeddings and Vector Store"
      ],
      "metadata": {
        "id": "GMrrjnWwgXnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Generates embeddings using Google's embedding-001 and stores them in a Chroma vector database,\n",
        "persisted to Google Drive. Configures a retriever to fetch relevant document chunks.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "EQqOAdkBgOHF",
        "outputId": "aa90147c-8f1c-4271-e070-cb78ace04b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nGenerates embeddings using Google's embedding-001 and stores them in a Chroma vector database,\\npersisted to Google Drive. Configures a retriever to fetch relevant document chunks.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize embedding model\n",
        "embedding_model_name = \"models/embedding-001\"\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=embedding_model_name)\n",
        "print(f\"Initialized embeddings: {embedding_model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC1gDNMAgdHn",
        "outputId": "36ec57ca-018c-4c69-9976-e8a517fa640c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized embeddings: models/embedding-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load or create Chroma vector store\n",
        "if os.path.exists(CHROMA_PATH):\n",
        "    print(f\"Loading vector store from {CHROMA_PATH}\")\n",
        "    vectorstore = Chroma(\n",
        "        persist_directory=CHROMA_PATH,\n",
        "        embedding_function=embeddings\n",
        "    )\n",
        "else:\n",
        "    print(f\"Creating vector store in {CHROMA_PATH}\")\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=docs,\n",
        "        embedding=embeddings,\n",
        "        persist_directory=CHROMA_PATH\n",
        "    )\n",
        "print(\"Vector store created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qbXSqTmgdBm",
        "outputId": "f986c521-9c09-46b3-9ed4-1a967afb9d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating vector store in /content/drive/MyDrive/chroma_db_ml_gemini\n",
            "Vector store created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure retriever to fetch top 5 relevant chunks\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "print(\"Retriever configured.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saZVe5FGeZRy",
        "outputId": "e3cac3d7-03a0-4538-e6d6-6d1e15764c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retriever configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 6: Initialize Language Model"
      ],
      "metadata": {
        "id": "8t2MiDNDgnYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Sets up the google/gemini-2.0-flash model.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8XO_lVeZguGk",
        "outputId": "7dd59242-ddd4-4f98-aa16-f43dcd5d481b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSets up the google/gemini-2.0-flash model.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Gemini model\n",
        "model = \"gemini-2.0-flash\"\n",
        "print(f\"Initializing model: {model}\")\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=model,\n",
        "    temperature=0.7,\n",
        "    max_output_tokens=1024,\n",
        "    top_p=0.95,\n",
        ")\n",
        "print(\"LLM initialized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raNlZOoMgt1O",
        "outputId": "4a52ec93-00f0-4577-e6c2-020c9084bb6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing model: gemini-2.0-flash\n",
            "LLM initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 7: Configure RAG Chain"
      ],
      "metadata": {
        "id": "G2Wd2FZ-g6HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Sets up the RAG pipeline with a custom prompt to ensure answers are based solely on the provided\n",
        "context. Combines the retriever and LLM for retrieval-augmented generation.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qFAAFtang-cq",
        "outputId": "37a30943-4ef0-4850-dafc-356856fee8d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSets up the RAG pipeline with a custom prompt to ensure answers are based solely on the provided\\ncontext. Combines the retriever and LLM for retrieval-augmented generation.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom prompt for RAG\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Context from Lecture Notes:\\n\"\n",
        "    \"{context}\\n\\n\"\n",
        "    \"Based on the above context, provide an answer to the following question.\\n\"\n",
        "    \"Summarize relevant information (e.g., bullet points, definitions) and answer ONLY the question asked.\\n\"\n",
        "    \"If the context does not contain the answer, respond with: \"\n",
        "    \"\\\"I cannot answer this question based on the provided notes.\\\"\\n\\n\"\n",
        "    \"Question: {input}\"\n",
        ")"
      ],
      "metadata": {
        "id": "KfDUpGOLg-T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create document chain to process retrieved documents\n",
        "document_chain = create_stuff_documents_chain(llm, prompt)"
      ],
      "metadata": {
        "id": "CY5jiLP4hJhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create RAG chain combining retriever and document chain\n",
        "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
        "print(\"RAG chain created. Ready to answer questions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOKLlMM2eY7X",
        "outputId": "72e765d5-1448-498e-aa9d-f556e299f595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG chain created. Ready to answer questions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 8: Interactive Chat Loop"
      ],
      "metadata": {
        "id": "thAmrGrGhMjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Implements an interactive chat loop for user queries. Supports caching for efficiency, verbose mode\n",
        "for source document display, and a Markdown-inspired output format for clarity.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "9us-I4sweY0H",
        "outputId": "cef113b7-0b3c-4d2d-a8e0-748c906a3146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nImplements an interactive chat loop for user queries. Supports caching for efficiency, verbose mode\\nfor source document display, and a Markdown-inspired output format for clarity.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc1cusYWePWY",
        "outputId": "c7fa13d0-a084-40c4-e4fa-70f71e7abc1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================\n",
            "    ðŸ¤– CTSE Lecture Notes Chatbot    \n",
            "======================================\n",
            "Enter your question or 'exit' to quit.\n",
            "Append '--verbose' to see source documents.\n",
            "\n",
            "â“ Question: explain ensemble methods --verbose\n",
            "\n",
            "â³ Processing...\n",
            "\n",
            "Question: explain ensemble methods\n",
            "\n",
            "Answer:\n",
            "*   **Definition:** Ensemble methods use a combination of multiple models (classifiers/predictors) to create an improved composite model.\n",
            "*   **Goal:** To create an improved composite model M* from a series of k learned models (M1, M2, M3, ..., Mk).\n",
            "*   **Process:**\n",
            "    *   Individual models make predictions.\n",
            "    *   These predictions are combined (e.g., through voting).\n",
            "    *   The combined result is the final prediction of the ensemble.\n",
            "*   **Examples:** Multiple decision trees, Bagging, Boosting, Boolean operator-based ensemble methods, ML based ensemble methods, Stack ensemble.\n",
            "*   **Motivation:** Often needed to solve real-world problems.\n",
            "*   **Prediction Mechanism:**\n",
            "    *   Each classifier's vote is assigned a score/weight based on its performance (lower error rate = higher weight).\n",
            "    *   Weight calculation: log((1 - error(Mi)) / error(Mi))\n",
            "    *   Class predictions from each classifier are weighted.\n",
            "    *   Weights for each predicted class are summed.\n",
            "    *   The class with the highest sum is selected as the final prediction.\n",
            "\n",
            "ðŸ“š Source Documents:\n",
            "\n",
            "- Source 1 (Page: 279):\n",
            "SLIIT  - Faculty of Computing\n",
            "Machine Learning â€“ SE4060\n",
            "Ensemble methods\n",
            "Methods that use a combination of Models. \n",
            " Ex: Multiple decision trees\n",
            "An ensemble method combines a series of k learned \n",
            "models(classifiers/predictors) with the aim of \n",
            "creating an improved composite model M*\n",
            " M1, M2, M3, â€¦â€¦,...\n",
            "----------------------------------------------------------------------------------------------------\n",
            "- Source 2 (Page: 292):\n",
            "SLIIT  - Faculty of Computing\n",
            "Machine Learning â€“ SE4060\n",
            "Other ensemble methods\n",
            "â€¢ Boolean operator-based ensemble methods\n",
            "â€¢ ML based ensemble methods\n",
            "â€¢ Stack ensemble\n",
            "52\n",
            "----------------------------------------------------------------------------------------------------\n",
            "- Source 3 (Page: 44):\n",
            "Ensemble Learning\n",
            "â€¢ Often, multiple classifiers need to be \n",
            "combined to solve a real-world problem.\n",
            "45\n",
            "----------------------------------------------------------------------------------------------------\n",
            "- Source 4 (Page: 280):\n",
            "SLIIT  - Faculty of Computing\n",
            "Machine Learning â€“ SE4060\n",
            "Ensemble methods\n",
            "Two techniques available:\n",
            "1. Bagging (Bootstrap aggregation)\n",
            "1. Boosting\n",
            "40\n",
            "----------------------------------------------------------------------------------------------------\n",
            "- Source 5 (Page: 287):\n",
            "SLIIT  - Faculty of Computing\n",
            "Machine Learning â€“ SE4060\n",
            "How an ensemble predict the class \n",
            "label of a new sample?\n",
            "â€¢ Assign a score/weight to each classifierâ€™s vote based on how well \n",
            "the classifier performed.\n",
            "â€¢ The lower the classifier error rate, the greater the accuracy. \n",
            "Therefore, the higher the...\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "ðŸ’¡ Ask another question or type 'exit' to quit!\n",
            "\n",
            "â“ Question: exit\n",
            "\n",
            "ðŸ‘‹ Exiting. Goodbye!\n"
          ]
        }
      ],
      "source": [
        "# Print chatbot introduction\n",
        "print(\"\\n======================================\")\n",
        "print(\"    ðŸ¤– CTSE Lecture Notes Chatbot    \")\n",
        "print(\"======================================\")\n",
        "print(\"Enter your question or 'exit' to quit.\")\n",
        "print(\"Append '--verbose' to see source documents.\\n\")\n",
        "\n",
        "# Main loop for user interaction\n",
        "while True:\n",
        "    query = input(\"â“ Question: \")\n",
        "\n",
        "    # Handle exit command\n",
        "    if query.strip().lower() == 'exit':\n",
        "        print(\"\\nðŸ‘‹ Exiting. Goodbye!\")\n",
        "        break\n",
        "\n",
        "    # Handle verbose mode and normalize query\n",
        "    verbose = False\n",
        "    if '--verbose' in query:\n",
        "        verbose = True\n",
        "        query = query.replace('--verbose', '').strip()\n",
        "\n",
        "    # Validate and normalize input\n",
        "    query = ' '.join(query.split())  # Remove extra spaces\n",
        "    if not query:\n",
        "        print(\"\\nâš ï¸ Error: Please enter a valid question.\")\n",
        "        continue\n",
        "\n",
        "    # Log processing\n",
        "    print(\"\\nâ³ Processing...\")\n",
        "\n",
        "    try:\n",
        "        # Check cache and validate response\n",
        "        if query in CACHE:\n",
        "            cached_answer = CACHE[query]['answer']\n",
        "            # Re-invoke if cached answer is the fallback response\n",
        "            if cached_answer == \"I cannot answer this question based on the provided notes.\":\n",
        "                result = rag_chain.invoke({\"input\": query})\n",
        "                CACHE[query] = {'answer': result['answer'], 'context': result['context']}\n",
        "            else:\n",
        "                print(f\"\\nQuestion: {query}\\n\")\n",
        "                print(\"Answer (Cached):\")\n",
        "                print(f\"{cached_answer}\\n\")\n",
        "                if verbose:\n",
        "                    print(\"ðŸ“š Source Documents (Cached):\")\n",
        "                    for i, doc in enumerate(CACHE[query]['context'], 1):\n",
        "                        print(f\"- Source {i} (Page: {doc.metadata.get('page', 'N/A')}):\")\n",
        "                        print(f\"{doc.page_content[:300]}{'...' if len(doc.page_content) > 300 else ''}\")\n",
        "                        print(\"\" + \"-\" * 100)\n",
        "                print(\"\\nðŸ’¡ Ask another question or type 'exit' to quit!\\n\")\n",
        "                continue\n",
        "\n",
        "        # Invoke RAG chain\n",
        "        result = rag_chain.invoke({\"input\": query})\n",
        "\n",
        "        # Cache response\n",
        "        CACHE[query] = {\n",
        "            'answer': result['answer'],\n",
        "            'context': result['context']\n",
        "        }\n",
        "\n",
        "        # Print refined terminal-friendly output\n",
        "        print(f\"\\nQuestion: {query}\\n\")\n",
        "        print(\"Answer:\")\n",
        "        print(f\"{result['answer']}\\n\")\n",
        "        if verbose:\n",
        "            print(\"ðŸ“š Source Documents:\\n\")\n",
        "            for i, doc in enumerate(result['context'], 1):\n",
        "                print(f\"- Source {i} (Page: {doc.metadata.get('page', 'N/A')}):\")\n",
        "                print(f\"{doc.page_content[:300]}{'...' if len(doc.page_content) > 300 else ''}\")\n",
        "                print(\"\" + \"-\" * 100)\n",
        "        print(\"\\nðŸ’¡ Ask another question or type 'exit' to quit!\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâš ï¸ Error: {e}\")\n",
        "        print(\"Please check your input, ensure the PDF is accessible, and verify your Hugging Face token.\")"
      ]
    }
  ]
}